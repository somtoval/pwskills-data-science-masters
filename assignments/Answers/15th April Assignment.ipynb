{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d277a38",
   "metadata": {},
   "source": [
    "# Q1. You are working on a machine learning project where you have a dataset containing numerical and categorical features. You have identified that some of the features are highly correlated and there are missing values in some of the columns. You want to build a pipeline that automates the feature engineering process and handles the missing values.\n",
    "\n",
    "## Design a pipeline that includes the following steps:\n",
    "* __Use an automated feature selection method to identify the important features in the dataset.__\n",
    "* __Create a numerical pipeline that includes the following steps.__\n",
    "* __Impute the missing values in the numerical columns using the mean of the column values.__\n",
    "* __Scale the numerical columns using standardisation.__\n",
    "* __Create a categorical pipeline that includes the following steps.__\n",
    "* __Impute the missing values in the categorical columns using the most frequent value of the column.__\n",
    "* __One-hot encode the categorical columns.__\n",
    "* __Combine the numerical and categorical pipelines using a ColumnTransformer.__\n",
    "* __Use a Random Forest Classifier to build the final model.__\n",
    "* __Evaluate the accuracy of the model on the test dataset.__\n",
    "\n",
    "__Note__: Your solution should include code snippets for each step of the pipeline, and a brief explanation of\n",
    "each step. You should also provide an interpretation of the results and suggest possible improvements for\n",
    "the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c076f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "# load the data\n",
    "df = sns.load_dataset('tips')\n",
    "\n",
    "#hot label encoding for Time feature\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder=LabelEncoder()\n",
    "df['time']=encoder.fit_transform(df['time'])\n",
    "\n",
    "## independent and dependent features\n",
    "X=df.drop(labels=['time'],axis=1)\n",
    "y=df['time']\n",
    "\n",
    "# split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# create a feature selection pipeline using SelectKBest and f_regression\n",
    "feature_selection_pipeline = Pipeline([\n",
    "    ('selector', SelectKBest(score_func=f_regression)),\n",
    "])\n",
    "\n",
    "# create a numerical pipeline using SimpleImputer and StandardScaler\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "# create a categorical pipeline using SimpleImputer and OneHotEncoder\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# combine the numerical and categorical pipelines using ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numerical_pipeline, X_train.select_dtypes(include=['float64', 'int64']).columns),\n",
    "    ('cat', categorical_pipeline, X_train.select_dtypes(include=['object']).columns)\n",
    "])\n",
    "\n",
    "# create the final pipeline by combining the feature selection and preprocessor pipelines with a RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('feat_select', feature_selection_pipeline),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# fit the pipeline to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the pipeline on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d755b59",
   "metadata": {},
   "source": [
    "In this code, X and y represent the dataset and the target variable, respectively. num_features and cat_features are the lists of the names of the numerical and categorical features, respectively. The code first splits the dataset into training and test sets. Then, it creates the numerical and categorical pipelines, which impute missing values and scale/encode the data, respectively. Next, it combines the pipelines using a ColumnTransformer. Finally, it builds the final pipeline with the preprocessor and a RandomForestClassifier as the classifier. The pipeline is fit on the training data and evaluated on the test data using the accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c3566",
   "metadata": {},
   "source": [
    "#  Q2. Build a pipeline that includes a random forest classifier and a logistic regression classifier, and then use a voting classifuir to combine their predictions. Train the pipeline on the iris dataset and evaluate its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06025b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the iris dataset and split it into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the individual classifiers\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Create the voting classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rfc', rfc), ('lr', lr)],\n",
    "    voting='hard'\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('voting', voting_clf)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the accuracy of the model on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150b80e6",
   "metadata": {},
   "source": [
    "In this code, X and y represent the dataset and the target variable, respectively. The code first splits the dataset into training and test sets. Then, it creates the individual classifiers: a RandomForestClassifier and a LogisticRegression classifier. Next, it creates a VotingClassifier that combines the two classifiers using hard voting. Finally, it creates a pipeline that scales the data and applies the VotingClassifier. The pipeline is fit on the training data and evaluated on the test data using the accuracy score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
